# Linux

## 文件映射

## IO 多路复用_select

### 使用

1. 申请资源/创建监听集合

    1. `fdset xxx`

2. 初始化集合

    1. `void FD_ZERO(fdset* set)`

    2. `void FD_CLR(int fd, fdset* set)`: 删除一个

3. 增加监听

    1. `void FD_SET(int fd, fdset* set)`

4. 进程调用 select (OS 轮询, 进程等待)

    1. `int select(int maxfd, fdset* rdset, fdset* wrset, fdset* excepset, struct timeval* timeout);`

    2. 返回值为 3 个就绪集合中的 fd 总数

    3. <mark>maxfd</mark> 为最大的文件描述符 + 1

    4. 读/写/异常集合, 没有填 `NULL`, 均为 **传入传出参数**, select 会将其修改为 就绪集合, 故 2/3 两步应放在循环内;  
        若 W 端关闭, 则 R 端立即返回 0, select 永远处于就绪状态, 故 读集合 就绪后需要对每个 R 端进行检查

    5. timeout 为单次轮询的最长时间, `NULL` 表示一直等

5. 文件描述符就绪, 返回就绪集合

    1. `void FD_ISSET(int fd, fdset* set)`: 检查是否存在

### 底层原理

1. 1024 bit 的位图

2. 1024 即为一个进程默认能够打开的最多的文件数量

### 运行流程

1. 将监听集合 由 <mark>用户态栈帧</mark>上 拷贝到 <mark>内核态</mark>

2. 内核轮询 [0, maxfd -1]

3. 轮询直到某 fd 就绪, 得到就绪集合

4. 将就绪集合 由 <mark>内核态</mark> 拷贝回 <mark>用户态</mark>

### select 缺陷 (与 epoll 区别, <mark>面试重点</mark>)

1. 上限 1024, 不好修改

2. 大量内核 与 用户态之间的 数据拷贝

3. 监听 与 就绪集合 耦合

4. 就绪检查不合理, 当海量连接少量就绪时 需要遍历所有连接, 依次判断是否就绪(FD_ISSET)

## IO 多路复用_epoll

### 改进

1. 数据结构分配在内核态文件对象

2. 文件对象内有两个集合 (监听/就绪)

3. 监听集合 底层实现为 <mark>红黑树</mark>, 方便新增, 查找效率高

    红黑树特点:

    1. 查找 O(logn)

    2. 结点是红或黑

    3. 根黑

    4. 红的父子黑

    5. 空叶子黑

    6. 黑色路径相同

4. 就绪集合 底层实现为 <mark>线性表</mark>, 用户只需便利就绪集合

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302054214.png)

### 步骤

1. 创建文件对象

    `int epoll_create(int size);`

    1. 参数无效, 填一个正整数

    2. 返回值为文件对象对应的文件描述符

2. 增加/移除 监听

    `int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event);`

    1. `epfd`: 文件对象 的 fd

    2. `op`:

        1. `EPOLL_CTL_ADD`

        2. `EPOLL_CTL_MOD`

        3. `EPOLL_CTL_DEL`

    3. `fd`: 即要监听的 fd

    4. `event`: 参数为 epoll_event 的地址; 设置监听事件类型 并设置 就绪后放到就绪集合里的东西 (一般为监听的 fd 自身); 若 移除监听时可直接填 `NULL`;

        ```c++
        struct epoll_event {
            // 就绪事件类型, 按位或 |
            // EPOLLIN 读就绪
            // EPOLLOUT 写就绪
            // EPOLLET 边缘触发
            uint32_t events;

            //  联合体, 只能存在一个
            epoll_data_t data;
        } 

        typedef union epoll_data {
            void* ptr;
            int fd;
            uint32_t u32;
            uint64_t u64;
        } epoll_data_t;
        ```

3. 内核轮训, 用户等待

   `int epoll_wait(int epfd, struct epoll_event* event, int maxevents, int timeout)`;

   1. 返回值 就绪集合的长度

   2. 参数为 `epoll_event` 数组的 首地址(数组名); 即为就绪集合

   3. `maxevents` 数组上限

   4. `timeout` 超时时间, 单位 ms, `-1` 表示永久等待

        ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302147315.png)

### epoll 触发机制

1. 边缘触发

    1. 只有 <mark>上升沿</mark> 才触发, 即 只看数据是否增加  

    2. 设置边缘触发: `epoll_ctl(..., &event)` 中 `event.events = EPOLLIN | EPOLLET`  

    3. 缺点: 某一次就绪只会读一部分数据, 有可能 数据残留; 可以使用 **while + 非阻塞 recv 解决**

    4. 为什么使用边缘触发(理由)

        1. 兼容性

            早期 epoll 只支持边缘促发

        2. 性能

            epoll_wait 与 recv 同一线程 <mark>水平触发</mark>  
            epoll_wait 与 recv 不同线程 <mark>边缘触发</mark>

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302152609.png)

2. 水平触发 (默认触发机制)

    只看字节数是否 > 0  

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302152033.png)

### 设置非阻塞  

1. `int fcntl(int fd, int cmd, ...);` 永久非阻塞 (管道/设备文件/socket)

    1. `F_GETFL` 获取状态作为返回值, 例 flag

    2. `F_SETFL` 设置状态为非阻塞(原状态上添加非阻塞属性), 例 `flag | O_NONBLOCK`

2. `recv(sockfd, buf, sizeof(buf), MSG_DONTWAIT);` 临时非阻塞 (sockfd)

## 5 种 IO 模型

1. 同步阻塞

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302251038.png)

2. 同步非阻塞

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302252198.png)

3. IO 多路复用

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302253101.png)

4. 异步 IO

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302254799.png)

5. 信号驱动 IO (异步)

    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309302254118.png)

    [ChatGPT](https://poe.com/s/liay9XtOV5DFFOtK85hD)

## 权限

## 进程相关命令

## 进程优先级

## 创建进程_system

## 创建进程_fork

## 创建进程_exec

## 孤儿进程_wait/waitpid

## 进程终止

## 守护进程

## gdb 调试

## 进程间通信_有名管道(named pipe)

### 概述

1. 有名 即 在文件系统中存在, but 该文件只能用于通信, 不能存储数据, 也不能用 vim 打开

2. 创建有名管道文件 `makefifo xxx`

3. named pipe 通信方式 为 半双工, but 一般单工使用, 使用 2 条 单工管道组成 1 条 全双工管道

### 使用

1. `open(filename, mode)`

    1. 打开模式: `O_RDONLY` / `O_WRONLY` 二选一;  
        若以 `O_RDWR` 方式打开, 则为非阻塞方式半双工通信

    2. 2 个进程 打开 2 个管道文件时 注意打开**顺序**, 获取资源的顺序不对会导致 <mark>死锁</mark>  

        例:  
        进程 1 先打开管道 A 读端, 后打开 B 写端;  
        进程 2 先打开管道 B 读端, 后打开 A 写端;  
        此时 进程 1/2 的 open 都被阻塞在第一步, 无法继续向下进行

2. `read()`

    1. 管道为空 且 W 端未关, 则<mark>阻塞</mark>, 类似设备文件 <------> 磁盘文件非空直接返回 0

    2. 管道为空 且 W 端已关, 则 读到文件终止符, 直接返回

3. `write()`

    1. 写完立刻返回, 写满会引发阻塞

    2. R 端已关, 写入会触发 `SIGPIPE`, 异常终止

4. `close()`

## 进程间通信_无名管道

只适合父子进程间通信

### 方式 1 (库函数)

![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309182203589.png)

1. 打开管道: `FILE* popen(const char* command, const char* type);`

    1. 根据 **command**, 启动一个子进程 (让子进程执行命令, 并将父子进程连通)

    2. 父子进程间存在一条通道

    3. type 表示 父进程管道的类型  

        `r` 表示 父读子写, 即重定向子进程的 **stdout**  

        `w` 表示 父写子读, 即重定向子进程的 **stdin**

2. 读写: `fread() / fwrite()`

3. 关闭管道: `fclose();`

### 方式 2 (系统调用)

![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/202309182223327.png)

1. `int pipe(int pipefd[2]);`

    1. 数组作为参数 会退化为指针, 2 只是起提示作用

    2. 整数数组用于储存 父子进程通信的 fd

    3. 数组中 第 0 项 为 R 端, 第 1 项 为 W 端

    4. 管道为 半双工, but 一般 单工使用

2. 创建子线程: `fork()`

3. 父进程关闭一端, 子进程关闭另一端, 使其成为单工

### 性质 (同有名管道)

1. 读阻塞

2. 写阻塞

3. 写端关闭, 读端返回 0

4. 读端关闭, 写入引发 `SIGPIPE`, 异常终止

### 管道缺点

1. 当 n 个进程进行通信时, 需要建的管道量级为 n<sup>2</sup>

2. 管道存在 阻塞 问题

## 进程间通信_共享内存

1. 特点

    1. 最快的 IPC (InterProcess communication);  

    2. 打破了部分 内存隔离性, 让不同进程的虚拟页映射到同一物理页;  

    3. 不需拷贝;

2. 步骤

    1. 让 OS 分配 共享的物理内存  

        `int shmget(key_t key, size_t size, int shmflag);`

        1. 返回 共享内存 id

        2. key 用于不同进程  定位 同一页共享内存  

            key = 0 (IPC_PRIVATE) 表示为 私有共享内存, 适用于父子进程 (`shmget() / shmat() / fork() ...`)

        3. size 为虚拟内存大小, 取 页的整数倍, 即 **n \* 4096B**

        4. shmflag 为 `IPC_CREAT | 0600`, 表示 不存在则创建 且 用户自己可读可写

    2. 让共享的 物理内存 加载到 进程地址空间 (分配虚拟内存)  

        `void* shmat(int shmid, const char* shmaddr, int shmflag);`

        1. 返回 虚拟内存首地址
        2. shmaddr 为 NULL
        3. shmflag 为 0

    3. 进程访问分配的内存

    4. 释放虚拟内存  
        `int shmdt(const void* shmaddr);`

### 缺点

存在竞争条件(race condition), 即 两个并发的执行流访问共享资源时 寄存器数据 跟不上 内存变量  

```shell
#单核运行
taskset -c 0 ...
```

### 补充

```shell
## 查看已存在的共享内存
ipcs 

## 删除共享内存, 延迟删除, nattach 为 0 时真正删除
ipcrm -a            ## 全删 
ipcrm -m shmid
ipcrm -M key
```

## 进程间通信_信号

### 特点

1. 信号是 软件层面 的 事件机制

2. 事件分为 同步 / 异步

3. 硬件层面 的是 中断

4. 信号的目标 总是 进程

### 信号处理阶段

1. 产生信号

    1. 硬件产生, 异步: `ctrl + c` / `ctrl + \`

    2. 硬件产生, 同步: `除 0 错误`

    3. 软件产生, 异步: `kill`

    4. 软件产生, 同步: `abort()`  

2. 递送信号 (delivery)

    1. 中止: `Term`

    2. 忽略: `Ign`

    3. 中止并生成 Core 文件: `Core`

    4. 暂停: `Stop`

    5. 恢复: `Cont`

### 注册信号

即 修改信号的 默认递送行为

1. 函数 1.1 (可读性较差)  

    `void (*signal(int sig, void (*func)(int)))(int);`

    1. 返回值: 返回值为 void, 参数为 int 的 **函数指针**

    2. 参数1: 整数

    3. 参数2: 返回值为 void, 参数为 int 的 **函数指针**

2. 函数 1.2

    `typedef void (*sighandler_t)(int);`  

    `sighandler_t signal(int signum, sighandler_t handler);`

    1. handler 为用户自己定义的递送函数, 由 OS 调用, 是为回调函数

    2. handler 为 `SIG_DFL`, 即采用信号的 默认递送行为

3. 函数 2

    `int sigaction(int signum, const struct sigaction* act, struct sigaction* oldact);`  

    ```c++
    struct sigaction {
        void (*sa_handler)(int);
        void (*sa_sigaction)(int, siginfo_t*, void*);
        sigset_t sa_mask;
        int sa_flags;
        void (*sa_restorer)(void);
    } 
    ```

    1. act 为要设置的新属性; oldact 用来保存旧的属性, 不保存可填 NULL

    2. `struct sigaction` 结构

        1. `sa_handler / sa_sigaction` 为回调函数, 只能存在一个

        2. `sa_mask` 额外临时屏蔽

        3. `sa_flags`  属性

            1. `0` 使用回调函数 1

            2. `SA_SIGINFO` 使用回调函数 2 传递 info 信息

            3. `SA_RESTART` 自动重启低速设备

            4. `SA_RESETHAND` 生效一次

            5. `SA_NODEFER` 递送时不屏蔽本信号

### 信号递送的核心数据结构

1. mask 掩码, 表示 某个过程 是否屏蔽了 某个信号

2. pending 位图, 表示 是否存在未决信号

3. 信号传入, 首先看 mask 是否屏蔽了该信号  

    若没有屏蔽, 则直接递送;  

    若屏蔽了, 则 将其先 移入 pending; 当 mask 从 有-->空 时, 看 pending, 有则取出递送
    ![](https://xiao060.oss-cn-hangzhou.aliyuncs.com/md/Snipaste_2023-09-18_23-54-29.png)

## signal 性质

1. 一次注册, 永久生效

2. 在递送信号时, 会**临时**屏蔽**本信号**, 不会屏蔽其他信号  
    sigprocmask 加上后是永久屏蔽

3. 进程因为**低速系统调用**而阻塞, 信号传递完成后会**自动重启**  
    低速系统调用指 有可能陷入永久阻塞的系统调用, 如 `read()`

## sigaction 默认性质

1. 一次注册, 永久生效 --------------> `SA_RESETHAND`

2. 递送过程临时屏蔽不能信号 ---------> `SA_NODEFER`

3. <mark>不会</mark> 自动重启低速设备 -------> `SA_RESTART`

## 多线程

### 子线程的创建

**编译**: `... -lpthread / -pthread` (新版本 Linux 不需要)

1. 主线程  

    main 函数启动

2. 子线程

    `int pthread_create(pthread_t* thread, const pthread_attr_t* attr, void* (*start_routine)(void*), void* arg);`

    1. `thread` 传入传出参数, 用来保存 子线程 id

    2. `attr` 子线程属性, 默认 `NULL`

    3. `start_routine`  **线程入口函数** 的 函数指针, 参数 为 `void*`, 返回值 为 `void*`

    4. 线程入口函数的 参数, 类型 为 `void*`, 在线程入口函数内需要强转成 需要的类型指针

### 子线程的终止

### 线程的取消

### 多线程资源清理

## 互斥

## 死锁

## 同步

### 同步流程

1. 准备共享数据  

    flag, mutex, cond

2. 先事件

    1. 事件 A

    2. 临界区改 flag

    3. pthread_cond_signal

3. 后事件

    1. 加锁

    2. while 判断条件, 满足则 `pthread_cond_wait`

    3. 解锁

    4. 事件 B

### 使用

1. 条件变量初始化

    1. 静态初始化

        `pthread_cond_t cond = PTHREAD_COND_INITIALIZER;`

    2. 动态初始化

        `int pthread_cond_init(pthread_cond_t* cond, pthread_condattr_t* cond_attr);`  

        第 2 个参数表示属性,填 NULL 即可

2. 等待 (线程入队)

    1. 永久等待

        `int pthread_cond_wait(pthread_cond_t* cond, pthread_mutex_t* mutex);`

    2. 具有超时时限的等待

        `int pthread_cond_timewait(pthread_cond_t* cond, pthread_mutex_t* mutex, const timespec* abstime);`

        第 3 个参数表示 绝对时间  

        但是 该函数一般不用来实现同步, 而是用来完成高精度定时

3. 唤醒

    1. 唤醒 1 个线程

        `int pthread_cond_signal(pthread_cond_t* cond);`

    2. 唤醒 所有线程

        `int pthread_cond_broadcast(pthread_cond_t* cond);`

4. 条件变量的销毁

    `int pthread_cond_destroy(pthread_cond_t* cond);`

### 底层原理

1. 条件变量底层: <mark>队列</mark>

2. `pthread_cond_wait` 过程

    其中 第 1 步 单独手动完成; 2-6步 由 `pthread_cond_wait` 完成

    1. 检查一下有没有 mutex, 有则上锁继续, 无则阻塞  

        因为 条件变量也属于共享资源, 所以对它的操作需要加锁进行

    2. 把本线程移入队列

    3. 解锁并陷入等待 (原子操作)

    4. 被唤醒

    5. 加锁

    6. 返回, 后续代码带锁运行
